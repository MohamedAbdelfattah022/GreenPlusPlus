{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW1o1TpHGMoQ"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTXB78sG7D9Y"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain==0.0.263"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9nXlSmsvf8M"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade numpy transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2I53i8HjUoz",
        "outputId": "ce4ca68d-37ef-4163-b5c6-aa5610879989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: langchain-core>=0.3.60 in /usr/local/lib/python3.11/dist-packages (from langchain_chroma) (0.3.66)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from langchain_chroma) (2.0.2)\n",
            "Collecting chromadb>=1.0.9 (from langchain_chroma)\n",
            "  Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.34.3)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading posthog-6.0.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.14.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.21.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (1.73.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain_chroma) (4.24.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.60->langchain_chroma) (0.4.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.60->langchain_chroma) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.3.60->langchain_chroma) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.60->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.25.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain_chroma) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain_chroma) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=1.0.9->langchain_chroma) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (0.33.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.6.1)\n",
            "Downloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
            "Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-6.0.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=b3e361d573b569b6af32bb292dad7a79873726b5385abda2577a06737a86017e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain_chroma\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.13 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain_chroma-0.2.4 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 overrides-7.7.0 posthog-6.0.1 pybase64-1.4.1 pypika-0.48.9 python-dotenv-1.1.1 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Collecting mistralai\n",
            "  Downloading mistralai-1.9.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.11.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mistralai) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10.3->mistralai) (4.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.9.1-py3-none-any.whl (381 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.8/381.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: eval-type-backport, mistralai\n",
            "Successfully installed eval-type-backport-0.2.2 mistralai-1.9.1\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.7.0\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.66)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain_community-0.3.26 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 typing-inspect-0.9.0\n",
            "Collecting langchain_mistralai\n",
            "  Downloading langchain_mistralai-0.2.10-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.3.66)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.21.2)\n",
            "Requirement already satisfied: httpx<1,>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (0.4.1)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_mistralai) (2.11.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.2->langchain_mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain_mistralai) (0.16.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (0.4.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_mistralai) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15.1->langchain_mistralai) (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (1.1.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.49->langchain_mistralai) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.2->langchain_mistralai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2.4.0)\n",
            "Downloading langchain_mistralai-0.2.10-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: langchain_mistralai\n",
            "Successfully installed langchain_mistralai-0.2.10\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting flask_cors\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting supabase\n",
            "  Downloading supabase-2.16.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting python-jwt\n",
            "  Downloading python_jwt-4.1.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Collecting gotrue<3.0.0,>=2.11.0 (from supabase)\n",
            "  Downloading gotrue-2.12.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
            "Collecting postgrest<1.2,>0.19 (from supabase)\n",
            "  Downloading postgrest-1.1.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting realtime<2.6.0,>=2.4.0 (from supabase)\n",
            "  Downloading realtime-2.5.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting storage3<0.13,>=0.10 (from supabase)\n",
            "  Downloading storage3-0.12.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting supafunc<0.11,>=0.9 (from supabase)\n",
            "  Downloading supafunc-0.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jwcrypto>=1.4.2 (from python-jwt)\n",
            "  Downloading jwcrypto-1.5.6-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.11.7)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
            "Collecting pytest-mock<4.0.0,>=3.14.0 (from gotrue<3.0.0,>=2.11.0->supabase)\n",
            "  Downloading pytest_mock-3.14.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
            "Requirement already satisfied: cryptography>=3.4 in /usr/local/lib/python3.11/dist-packages (from jwcrypto>=1.4.2->python-jwt) (43.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from jwcrypto>=1.4.2->python-jwt) (4.14.0)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<1.2,>0.19->supabase)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: websockets<16,>=11 in /usr/local/lib/python3.11/dist-packages (from realtime<2.6.0,>=2.4.0->supabase) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from storage3<0.13,>=0.10->supabase) (2.9.0.post0)\n",
            "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.11,>=0.9->supabase)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.4->jwcrypto>=1.4.2->python-jwt) (1.17.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<3.0.0,>=2.1.0->postgrest<1.2,>0.19->supabase) (24.2)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.4.1)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.11/dist-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->storage3<0.13,>=0.10->supabase) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.4->jwcrypto>=1.4.2->python-jwt) (2.22)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.6.0)\n",
            "Downloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading supabase-2.16.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_jwt-4.1.0-py2.py3-none-any.whl (7.1 kB)\n",
            "Downloading gotrue-2.12.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jwcrypto-1.5.6-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading postgrest-1.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading realtime-2.5.3-py3-none-any.whl (21 kB)\n",
            "Downloading storage3-0.12.0-py3-none-any.whl (18 kB)\n",
            "Downloading supafunc-0.10.1-py3-none-any.whl (8.0 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pytest_mock-3.14.1-py3-none-any.whl (9.9 kB)\n",
            "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Installing collected packages: strenum, realtime, pyngrok, deprecation, pytest-mock, jwcrypto, flask_cors, supafunc, storage3, python-jwt, postgrest, gotrue, supabase\n",
            "Successfully installed deprecation-2.1.0 flask_cors-6.0.1 gotrue-2.12.2 jwcrypto-1.5.6 postgrest-1.1.1 pyngrok-7.2.11 pytest-mock-3.14.1 python-jwt-4.1.0 realtime-2.5.3 storage3-0.12.0 strenum-0.4.15 supabase-2.16.0 supafunc-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_chroma\n",
        "!pip install mistralai\n",
        "!pip install pypdf\n",
        "!pip install langchain_community\n",
        "!pip install langchain_mistralai\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "!pip install flask pyngrok flask_cors supabase python-jwt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CnGUC2HGMoU"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U --quiet langchain-community tiktoken langchain-openai langchainhub chromadb langchain langgraph langchain-text-splitters langchain-experimental\n",
        "!pip install langchain-ollama\n",
        "!pip install langchain_groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJrkkutDR8_v"
      },
      "source": [
        "# Pulling LLM Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmNx7CSXNRjY",
        "outputId": "001a2e27-2dde-42d4-92e2-fe23565e79be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13281    0 13281    0     0  54675      0 --:--:-- --:--:-- --:--:-- 54880\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiz_FCi-NXry"
      },
      "outputs": [],
      "source": [
        "ollama_model_id_1 = \"llama3.2\"\n",
        "ollama_model_id_2 = \"deepseek-r1:7b\"\n",
        "ollama_model_id_3 = \"nomic-embed-text\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ifk78HONZlu",
        "outputId": "2abf79bc-bc1c-4f50-970c-166ca4c7cf2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Your new public key is: \n",
            "\n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIESeK+o94/rvdqJ2W12ecJLgYuLLvPLs5xXm63q2HzyR\n",
            "\n",
            "time=2025-07-02T16:30:39.724Z level=INFO source=routes.go:1235 msg=\"server config\" env=\"map[CUDA_VISIBLE_DEVICES: GPU_DEVICE_ORDINAL: HIP_VISIBLE_DEVICES: HSA_OVERRIDE_GFX_VERSION: HTTPS_PROXY: HTTP_PROXY: NO_PROXY: OLLAMA_CONTEXT_LENGTH:4096 OLLAMA_DEBUG:INFO OLLAMA_FLASH_ATTENTION:false OLLAMA_GPU_OVERHEAD:0 OLLAMA_HOST:http://127.0.0.1:11434 OLLAMA_INTEL_GPU:false OLLAMA_KEEP_ALIVE:5m0s OLLAMA_KV_CACHE_TYPE: OLLAMA_LLM_LIBRARY: OLLAMA_LOAD_TIMEOUT:5m0s OLLAMA_MAX_LOADED_MODELS:0 OLLAMA_MAX_QUEUE:512 OLLAMA_MODELS:/root/.ollama/models OLLAMA_MULTIUSER_CACHE:false OLLAMA_NEW_ENGINE:false OLLAMA_NOHISTORY:false OLLAMA_NOPRUNE:false OLLAMA_NUM_PARALLEL:0 OLLAMA_ORIGINS:[http://localhost https://localhost http://localhost:* https://localhost:* http://127.0.0.1 https://127.0.0.1 http://127.0.0.1:* https://127.0.0.1:* http://0.0.0.0 https://0.0.0.0 http://0.0.0.0:* https://0.0.0.0:* app://* file://* tauri://* vscode-webview://* vscode-file://*] OLLAMA_SCHED_SPREAD:false ROCR_VISIBLE_DEVICES: http_proxy: https_proxy: no_proxy:]\"\n",
            "time=2025-07-02T16:30:39.725Z level=INFO source=images.go:476 msg=\"total blobs: 0\"\n",
            "time=2025-07-02T16:30:39.725Z level=INFO source=images.go:483 msg=\"total unused blobs removed: 0\"\n",
            "time=2025-07-02T16:30:39.725Z level=INFO source=routes.go:1288 msg=\"Listening on 127.0.0.1:11434 (version 0.9.3)\"\n",
            "time=2025-07-02T16:30:39.725Z level=INFO source=gpu.go:217 msg=\"looking for compatible GPUs\"\n",
            "time=2025-07-02T16:30:40.038Z level=INFO source=types.go:130 msg=\"inference compute\" id=GPU-0e03bcca-de9f-51ac-765c-106b529de8c8 library=cuda variant=v12 compute=7.5 driver=12.4 name=\"Tesla T4\" total=\"14.7 GiB\" available=\"14.6 GiB\"\n"
          ]
        }
      ],
      "source": [
        "# !nohup bash -c \"OLLAMA_HOST=0.0.0.0:8000 OLLAMA_ORIGIN=* ollama serve\" &\n",
        "!nohup bash -c \"ollama serve\" &\n",
        "!sleep 5 && tail /content/nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwPqTjMpNdB2"
      },
      "outputs": [],
      "source": [
        "# !ollama pull {ollama_model_id_1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGDlz1KCNfp5"
      },
      "outputs": [],
      "source": [
        "# !nohup ollama run {ollama_model_id_1} &\n",
        "# !sleep 1 && tail /content/nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54cV2bT9Nzx6"
      },
      "outputs": [],
      "source": [
        "# !ollama pull {ollama_model_id_2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b304lhpQN2p4"
      },
      "outputs": [],
      "source": [
        "# !nohup ollama run {ollama_model_id_2} &\n",
        "# !sleep 1 && tail /content/nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUMcxRsaO5H4",
        "outputId": "0f8b490b-6c76-4415-c18f-cb33c2fa647b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ],
      "source": [
        "!ollama pull {ollama_model_id_3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpov9Y8dO7m9",
        "outputId": "9b09c11d-3b76-47c0-baf5-cdbff90a59bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "[GIN] 2025/07/02 - 16:30:44 | 200 |      64.828µs |       127.0.0.1 | HEAD     \"/\"\n",
            "time=2025-07-02T16:30:45.719Z level=INFO source=download.go:177 msg=\"downloading 970aa74c0a90 in 3 100 MB part(s)\"\n",
            "time=2025-07-02T16:30:47.982Z level=INFO source=download.go:177 msg=\"downloading c71d239df917 in 1 11 KB part(s)\"\n",
            "time=2025-07-02T16:30:49.450Z level=INFO source=download.go:177 msg=\"downloading ce4a164fc046 in 1 17 B part(s)\"\n",
            "time=2025-07-02T16:30:50.709Z level=INFO source=download.go:177 msg=\"downloading 31df23ea7daa in 1 420 B part(s)\"\n",
            "[GIN] 2025/07/02 - 16:30:53 | 200 |  8.636364168s |       127.0.0.1 | POST     \"/api/pull\"\n",
            "[GIN] 2025/07/02 - 16:30:53 | 200 |      34.545µs |       127.0.0.1 | HEAD     \"/\"\n",
            "[GIN] 2025/07/02 - 16:30:53 | 200 |   21.231044ms |       127.0.0.1 | POST     \"/api/show\"\n",
            "[GIN] 2025/07/02 - 16:30:53 | 400 |   13.586367ms |       127.0.0.1 | POST     \"/api/generate\"\n",
            "\u001b[?25l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[K\u001b[?25h\u001b[?2026l\u001b[2K\u001b[1G\u001b[?25hError: \"nomic-embed-text\" does not support generate\n"
          ]
        }
      ],
      "source": [
        "!nohup ollama run {ollama_model_id_3} &\n",
        "!sleep 1 && tail /content/nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MWOyKOIN_vR"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# curl http://localhost:11434/api/chat -d '{\n",
        "#   \"model\": \"deepseek-r1:7b\",\n",
        "#   \"stream\": true,\n",
        "#   \"messages\": [\n",
        "#     { \"role\": \"user\", \"content\": \"what is the capital of egypt\" }\n",
        "#   ]\n",
        "# }'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4IABZPsOHx5"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# curl http://localhost:11434/api/chat -d '{\n",
        "#   \"model\": \"llama3.2\",\n",
        "#   \"stream\": true,\n",
        "#   \"messages\": [\n",
        "#     { \"role\": \"user\", \"content\": \"ما عاصمة مصر؟\" }\n",
        "#   ]\n",
        "# }'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puCvDOV0PJVC",
        "outputId": "1677beec-5b9b-417e-cf98-cbb073afacec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"embedding\":[0.596611738204956,0.4038065969944,-3.301659345626831,-0.527764081954956,0.7528295516967773,1.5176159143447876,-0.12341324985027313,0.3994874060153961,0.07080785185098648,-1.1066460609436035,0.6891273856163025,1.2791866064071655,1.1506240367889404,1.0897144079208374,0.24736447632312775,0.2913069427013397,0.14929239451885223,-0.6370189785957336,-0.20820362865924835,-0.20084066689014435,-1.7955728769302368,-0.6318198442459106,0.03730666637420654,-0.6715432405471802,1.2628475427627563,1.2765344381332397,-0.16518892347812653,-0.0018886495381593704,-0.29799869656562805,-0.48259031772613525,1.2042748928070068,-0.6338313221931458,-0.5424551367759705,-1.0355058908462524,0.6290382742881775,-1.2067773342132568,0.6842918992042542,-0.05698380619287491,-0.19483155012130737,0.12923064827919006,-0.018023675307631493,-0.5538797974586487,0.3511584401130676,0.047945208847522736,0.6018522381782532,-0.957679271697998,0.5084206461906433,1.5722949504852295,-0.7101343870162964,-0.38054630160331726,-0.6738687753677368,1.1416372060775757,-0.10838398337364197,-1.9447559118270874,0.4668470025062561,1.437364101409912,0.5073143839836121,-0.3435628116130829,0.5022619366645813,0.08047568053007126,1.3476357460021973,1.79447603225708,0.09421845525503159,1.1037598848342896,1.3005530834197998,-0.9233483672142029,-1.1415046453475952,-0.1893899142742157,0.19687822461128235,-0.3267350494861603,1.4743890762329102,-1.2659586668014526,0.06497234851121902,0.7983435392379761,-0.5999121069908142,-1.1105527877807617,-1.3123114109039307,0.4155399799346924,-0.10726697742938995,1.0695700645446777,0.3272382915019989,0.44006097316741943,0.4644833207130432,0.2225322127342224,1.2034796476364136,0.612824022769928,0.7478929758071899,-0.35485178232192993,-0.30607929825782776,-0.13049882650375366,0.1651797741651535,-0.5772202014923096,1.421271562576294,0.2021683007478714,-0.4536314606666565,-0.1230991780757904,-0.6094827055931091,1.4640828371047974,-1.3463176488876343,-0.6415805816650391,-1.182835340499878,-0.5092137455940247,-0.9118468761444092,0.7179521918296814,1.5051218271255493,0.5314150452613831,-0.22863730788230896,-0.1808173954486847,-0.607716977596283,-0.9503152966499329,0.18992497026920319,0.6948076486587524,-0.08356841653585434,0.04444463923573494,-0.21146120131015778,-1.4184205532073975,0.09423966705799103,-0.879564106464386,0.24458087980747223,1.9921761751174927,0.8835241198539734,-0.07445045560598373,0.0839996188879013,-0.35051360726356506,-0.21258778870105743,1.0222899913787842,-0.611575722694397,0.00942428782582283,0.26715683937072754,-1.0353208780288696,-0.7315455079078674,-0.7651793956756592,-0.0933900997042656,0.2760028541088104,0.10075954347848892,0.4392056167125702,-0.19629773497581482,-0.8400853872299194,0.13278190791606903,0.4153699576854706,0.8136956095695496,0.453166663646698,0.978903591632843,-0.6697325706481934,-0.1165512204170227,-1.3586668968200684,0.5920721888542175,-0.02021847851574421,-0.2403138130903244,-0.7177209258079529,-0.5492299199104309,-0.18326786160469055,0.41206029057502747,0.6442871689796448,0.10592977702617645,-1.110182762145996,0.5376916527748108,-0.1994509994983673,0.5514219999313354,0.6689451336860657,1.0992352962493896,0.4787495732307434,-0.2538961172103882,0.46902701258659363,-0.48571154475212097,-0.6594177484512329,1.1181823015213013,0.8031982183456421,0.662143886089325,0.7644698023796082,-1.094913125038147,-1.6800189018249512,-0.5539228916168213,-0.9314845204353333,-0.04931744560599327,0.18482080101966858,1.4208881855010986,-0.4571005702018738,0.18980252742767334,-0.8143535852432251,-0.23008179664611816,-1.394913673400879,0.30193692445755005,0.16031041741371155,0.5493873357772827,0.042138226330280304,-1.172319769859314,-0.816856324672699,-0.7298208475112915,-0.5520516633987427,-0.2304537147283554,-0.5417223572731018,-1.4013811349868774,-0.9245904088020325,0.21267491579055786,-0.4855476915836334,1.1404117345809937,1.0108745098114014,0.3550950586795807,0.3664192855358124,-0.13744419813156128,-0.3154374957084656,0.4818825423717499,-0.21868471801280975,0.23371616005897522,1.2752426862716675,0.27600178122520447,0.9312672019004822,-1.1442681550979614,0.10080569982528687,1.2236602306365967,-0.3910464346408844,0.2293361872434616,-0.12960609793663025,1.2129926681518555,0.09096094965934753,-0.9758371114730835,-0.02253013476729393,-0.2818033993244171,1.6926413774490356,-0.46480971574783325,0.3644765615463257,0.6455419659614563,-0.4644624590873718,0.8193121552467346,0.036009568721055984,-0.6319578289985657,0.1379246860742569,0.9435267448425293,-0.3511826992034912,0.20689649879932404,0.28290611505508423,0.687075674533844,0.7111847996711731,0.6212663054466248,0.8290323615074158,0.43868395686149597,1.197878122329712,-0.19497549533843994,-0.004770632833242416,-0.8353025317192078,1.342053771018982,-1.5082056522369385,0.2653544545173645,-0.9808100461959839,1.0033750534057617,-0.45849886536598206,-0.39256277680397034,-0.8312278985977173,-0.0036808252334594727,0.73320472240448,0.09787164628505707,0.6167395710945129,1.0272433757781982,0.023303255438804626,-1.6345181465148926,-1.2574732303619385,0.07179759442806244,-0.06611626595258713,-1.0671790838241577,-0.6621577739715576,-0.8173157572746277,0.9018567204475403,-1.538090467453003,-1.2504180669784546,1.1567376852035522,-0.5349427461624146,0.5186052322387695,0.39508652687072754,-1.513311743736267,0.6608579754829407,0.5536298155784607,0.42713016271591187,0.2594867944717407,0.2382032573223114,-0.5782996416091919,0.36620089411735535,-0.6149708032608032,-0.10820846259593964,0.9322540163993835,-0.34781453013420105,-0.17581503093242645,-0.6907083988189697,-0.1995164304971695,0.29979243874549866,0.2964015305042267,0.5056819319725037,1.5905321836471558,0.00990174151957035,0.9876900911331177,0.7938240170478821,0.21945475041866302,0.6569220423698425,1.6160863637924194,-0.461373507976532,0.690303385257721,1.3450679779052734,0.061776865273714066,0.7100813388824463,-0.8052645921707153,0.27112340927124023,0.3896143436431885,1.0244975090026855,0.1449095457792282,-0.05437922477722168,0.27929237484931946,0.046091530472040176,0.3825424909591675,0.4757801592350006,-0.5945715308189392,-0.2099483162164688,1.192258596420288,-0.5413431525230408,1.9740772247314453,-0.685494601726532,1.1660597324371338,0.5568597912788391,-0.006429770030081272,0.6852979063987732,0.6798750758171082,0.3858884274959564,-0.6941286325454712,0.4736044108867645,-0.1331615447998047,0.5947201251983643,0.7879973649978638,-0.8968677520751953,0.9747558236122131,-0.7986097931861877,-1.0501357316970825,-0.2135218381881714,0.5571238398551941,0.42839139699935913,-0.4009246826171875,-1.4893555641174316,-0.1762353479862213,-0.19898667931556702,-1.1195495128631592,-0.43501564860343933,1.1508671045303345,1.2911837100982666,-1.7641068696975708,-0.15243767201900482,-1.0906763076782227,-0.43505796790122986,-0.32116326689720154,-0.11491089314222336,-0.2265586107969284,0.5630074143409729,-0.3280337154865265,-0.35613518953323364,0.12498334050178528,0.14978930354118347,-0.2567434310913086,-0.5006039142608643,0.31109970808029175,-0.5565162301063538,0.5325968861579895,0.9118931889533997,-0.004447425715625286,0.21498051285743713,-1.0382307767868042,-0.20909443497657776,-0.2842057943344116,-0.7384029030799866,0.7601131200790405,0.185438871383667,0.3847975730895996,0.07829780131578445,-0.2608492970466614,-0.706405520439148,-0.26946765184402466,-0.8520636558532715,1.091347336769104,0.26609694957733154,0.18803590536117554,-0.6470011472702026,-1.2459783554077148,0.43427547812461853,0.18813186883926392,-0.5077468752861023,0.6880239844322205,0.022120490670204163,0.4516860246658325,-0.01980581507086754,0.36271220445632935,-0.49404656887054443,-1.1517653465270996,-0.46668440103530884,-0.6133459210395813,-0.25544601678848267,-1.2270203828811646,-0.40044790506362915,-0.04076951742172241,0.36222249269485474,-1.3018567562103271,1.1129164695739746,-0.4887944757938385,-0.4470321536064148,0.4242391586303711,-0.5528107285499573,-0.759588897228241,-0.49011731147766113,-1.2200953960418701,-0.038047611713409424,0.608284056186676,-0.15999509394168854,-1.5344606637954712,1.130014419555664,0.9397381544113159,0.5193549394607544,0.7948578000068665,-0.15295174717903137,-2.24099063873291,-0.009223559871315956,0.03987658768892288,0.4352607727050781,0.07371846586465836,0.3698995113372803,0.2781955599784851,1.4790211915969849,1.0919923782348633,0.1882440447807312,-0.4373933672904968,0.9348320960998535,0.3632541596889496,0.22158417105674744,0.5447224974632263,0.423174649477005,-1.0663633346557617,0.05321343243122101,-0.21944230794906616,-0.4225231111049652,-0.23518963158130646,-1.212566614151001,0.5283460021018982,-0.35358744859695435,-0.19479885697364807,0.289979487657547,1.6998915672302246,1.1239995956420898,-1.426933765411377,-0.591568112373352,-1.2233365774154663,1.4709141254425049,2.432877540588379,0.2987994849681854,-2.2052388191223145,-0.818899929523468,0.39353981614112854,-0.36842384934425354,-1.0225803852081299,0.8729929327964783,1.6586236953735352,1.8521302938461304,-0.11706165224313736,-0.5797351598739624,0.47949764132499695,1.0777664184570312,1.7730516195297241,0.61417555809021,0.14451919496059418,-0.14026616513729095,-0.07412111759185791,0.28307077288627625,-0.2503310441970825,-0.15859661996364594,-0.13645072281360626,0.132460355758667,0.6617013216018677,-1.1295521259307861,-0.22827641665935516,0.361577570438385,-0.6985985040664673,-1.2107559442520142,0.08879562467336655,-1.4294335842132568,-0.0606250986456871,0.7149401307106018,1.1364094018936157,0.46839794516563416,0.7382111549377441,-0.3085472285747528,-0.9128619432449341,-0.5712950229644775,1.6387861967086792,0.19342255592346191,0.3440253734588623,0.3345757722854614,-0.6178752183914185,0.5685961842536926,-0.7125232815742493,0.2161216288805008,-0.19364379346370697,0.4715735912322998,-0.36006492376327515,0.26813340187072754,-0.5475116968154907,0.06676196306943893,0.047828108072280884,0.048004090785980225,0.4453081488609314,0.5079702734947205,0.38606053590774536,-0.5544606447219849,0.38449594378471375,0.7188999056816101,-0.7919629216194153,-0.28655385971069336,1.2777585983276367,-0.49606284499168396,-1.6970856189727783,1.5111522674560547,0.19060102105140686,-0.07616302371025085,-1.0408554077148438,-0.3262596130371094,0.9272560477256775,-0.5220814347267151,-0.27131104469299316,0.5542806386947632,-0.633391797542572,-0.41792812943458557,0.18687093257904053,-0.8607949614524841,1.1215674877166748,-0.0623738095164299,-0.7583239674568176,0.4652816355228424,0.3405047357082367,0.04031549394130707,0.2570338845252991,-0.6417819261550903,-0.7205320000648499,0.6786131858825684,-0.496814489364624,-0.2949983477592468,0.9962171316146851,-0.0038913246244192123,0.894688606262207,0.023441269993782043,0.5082686543464661,0.4546356499195099,-0.008820895105600357,-0.2593657374382019,0.23540456593036652,-1.4155504703521729,0.3332231640815735,1.3773936033248901,-0.4247310757637024,0.6520944237709045,-0.9119656085968018,0.5188640356063843,0.2496802806854248,1.1793019771575928,-0.5495083332061768,0.13620063662528992,-0.34838902950286865,-1.1845099925994873,0.11421182751655579,0.11526980996131897,0.279660165309906,0.1937248557806015,0.17726927995681763,1.1113967895507812,-1.3886826038360596,-0.02917817234992981,0.454542875289917,0.3746641278266907,0.012863422743976116,-0.04183897376060486,-0.4016326367855072,-0.5208070874214172,-0.530788779258728,-0.14520616829395294,0.35424813628196716,0.19974388182163239,0.12470437586307526,-1.0574290752410889,-0.44522762298583984,1.1787713766098022,0.06322960555553436,1.1563111543655396,-0.047420185059309006,-0.31989672780036926,-0.46688705682754517,0.22948887944221497,-1.1282330751419067,1.759867548942566,-1.0145319700241089,-0.4665185213088989,-0.25759658217430115,-0.5989101529121399,-0.8220952153205872,-0.268137663602829,-1.0793370008468628,-0.26433688402175903,-0.9908605217933655,-1.810337781906128,-0.07210736721754074,0.4463964104652405,-0.7295593619346619,1.0570154190063477,-1.022916555404663,0.3224487602710724,0.3827787935733795,-0.10382390767335892,-0.964362621307373,0.34398627281188965,-0.29836732149124146,0.37425747513771057,-0.4190165400505066,0.12424048781394958,-0.17750480771064758,0.06980859488248825,-1.2893588542938232,1.3699705600738525,-0.07389415800571442,0.7179818153381348,-2.0178496837615967,-0.13188695907592773,-1.9673259258270264,0.37154966592788696,-1.1174101829528809,1.168243646621704,-0.9618223905563354,-1.1637318134307861,-1.1128607988357544,0.7947219610214233,0.7270287275314331,-0.07695959508419037,0.8235002756118774,-0.2530231475830078,-0.3969663977622986,-0.06334580481052399,0.43208277225494385,-0.22821617126464844,0.6416243314743042,0.5933946371078491,0.5161401629447937,0.2904685437679291,1.017472267150879,0.3477233946323395,-0.43336841464042664,1.0115700960159302,-0.16126297414302826,1.1720529794692993,-0.45413142442703247,0.03891567513346672,-0.8873960971832275,1.289166808128357,0.7298948168754578,0.5521595478057861,-0.96771639585495,0.6098096370697021,-0.48191970586776733,0.5408534407615662,0.1493312567472458,-0.4702226519584656,-2.071690559387207,-1.0564754009246826,-0.10154920816421509,-2.1714041233062744,0.18001121282577515,0.6793662905693054,-0.5380242466926575,0.284769207239151,-0.5594838857650757,-1.7851669788360596,0.13525769114494324,-0.8120720982551575,0.5468419790267944,-0.4257524013519287,-0.4457937777042389,-0.011865351349115372,-0.2414010465145111,0.43063884973526,0.8471792936325073,0.5104038715362549,-0.07989782094955444,0.9365085363388062,0.9143933057785034,-0.3032689690589905,-0.2668214440345764,-0.3113429546356201,-0.20978137850761414,-0.41722047328948975,-0.2833954691886902,0.629489004611969,-2.4666173458099365,0.4440686106681824,0.39702320098876953,-1.2595996856689453,-1.5507508516311646,0.4905312955379486,-0.6933292150497437,0.3380364179611206,-0.6400011777877808,0.40775373578071594,-0.40219008922576904,-1.1780387163162231,-0.11065209656953812,0.37948179244995117,0.8448335528373718,0.13452452421188354,-0.9455470442771912,0.4914744794368744,-0.4470999836921692,-0.21429657936096191,-0.08379240334033966,-0.30885156989097595,0.5806231498718262,0.3542720377445221,0.9969640374183655,0.11141970753669739,0.3750711977481842,-0.10743381083011627,0.26700013875961304,-0.604420006275177,1.0206973552703857,0.8106960654258728,-0.36516568064689636,-0.6259576082229614,-1.4596701860427856,-0.040029652416706085,-0.41633808612823486,0.6577274799346924,-1.4596110582351685,-0.09516552090644836,-0.653337299823761,0.1119464859366417,1.0175315141677856,-0.25507399439811707,0.5042980313301086,-0.34695523977279663,-0.8164779543876648,-0.577079713344574,0.13891853392124176,-0.04879584163427353,-0.3081592321395874,-1.3044885396957397,0.24270662665367126,0.20688128471374512,0.3283151090145111,0.017381979152560234,-0.4584950804710388,0.2928582429885864,0.5352063775062561,1.4805874824523926,-0.36589449644088745,0.4414066970348358,0.22818776965141296,-0.15724222362041473,0.34908780455589294,0.425024151802063,0.6885184645652771,0.4411327838897705,-0.018926845863461494,2.034940481185913,-0.05141178518533707,0.45415663719177246,-0.22181059420108795,0.34288108348846436,0.7063103318214417,-1.1499360799789429,-0.14816659688949585,-0.5441664457321167,0.46863630414009094]}"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    95    0     0  100    95      0     79  0:00:01  0:00:01 --:--:--    79\r100 15279    0 15184  100    95   8703     54  0:00:01  0:00:01 --:--:--  8755\r100 15279    0 15184  100    95   8703     54  0:00:01  0:00:01 --:--:--  8755\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "curl http://localhost:11434/api/embeddings -d '{\n",
        "  \"model\": \"nomic-embed-text\",\n",
        "  \"prompt\": \"The sky is blue because of Rayleigh scattering\"\n",
        "}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UXrbENpz67S",
        "outputId": "66526a51-cd60-4025-c962-9eec7adc81b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available model IDs:\n",
            "- llama3-8b-8192\n",
            "- llama3-70b-8192\n",
            "- whisper-large-v3-turbo\n",
            "- qwen-qwq-32b\n",
            "- playai-tts\n",
            "- meta-llama/llama-prompt-guard-2-86m\n",
            "- distil-whisper-large-v3-en\n",
            "- deepseek-r1-distill-llama-70b\n",
            "- playai-tts-arabic\n",
            "- allam-2-7b\n",
            "- meta-llama/llama-prompt-guard-2-22m\n",
            "- whisper-large-v3\n",
            "- meta-llama/llama-guard-4-12b\n",
            "- llama-3.3-70b-versatile\n",
            "- meta-llama/llama-4-scout-17b-16e-instruct\n",
            "- compound-beta\n",
            "- mistral-saba-24b\n",
            "- compound-beta-mini\n",
            "- qwen/qwen3-32b\n",
            "- meta-llama/llama-4-maverick-17b-128e-instruct\n",
            "- gemma2-9b-it\n",
            "- llama-3.1-8b-instant\n",
            "\n",
            "Model info:\n",
            "{'id': 'llama3-70b-8192', 'object': 'model', 'created': 1693721698, 'owned_by': 'Meta', 'active': True, 'context_window': 8192, 'public_apps': None, 'max_completion_tokens': 8192}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('groq_key')\n",
        "url = \"https://api.groq.com/openai/v1/models\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "models = response.json()\n",
        "\n",
        "print(\"Available model IDs:\")\n",
        "for model in models.get(\"data\", []):\n",
        "    print(\"-\", model.get(\"id\"))\n",
        "\n",
        "target_model = \"llama3-70b-8192\"\n",
        "found = next((m for m in models.get(\"data\", []) if m.get(\"id\") == target_model), None)\n",
        "\n",
        "if found:\n",
        "    print(\"\\nModel info:\")\n",
        "    print(found)\n",
        "else:\n",
        "    print(f\"\\nModel {target_model} not found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaDdBBDH2d2Y",
        "outputId": "0494c815-653a-4406-e252-9c2f0a95162a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In hot climates, it's essential to use insulation materials that can effectively reduce heat gain, minimize energy consumption, and provide a comfortable living space. Here are some of the best insulation materials for hot climates:\n",
            "\n",
            "1. **Fiberglass batts with radiant barrier**: Fiberglass batts are a popular choice for hot climates because they are inexpensive and easy to install. Adding a radiant barrier, such as aluminum foil, to the fiberglass batts can reflect up to 97% of radiant heat, reducing heat gain in the summer.\n",
            "2. **Reflective insulation**: Radiant barrier insulation, like Reflectix or Astro-Foil, is designed to reflect radiant heat rather than absorb it. This type of insulation is ideal for attics, crawl spaces, and radiant floor systems.\n",
            "3. **Spray foam insulation**: Closed-cell spray foam insulation, such as polyisocyanurate (PIR) or polyurethane (PUR), provides high R-values ( thermal resistance) and can be used in walls, floors, and ceilings. It's an excellent choice for hot climates because it can help reduce air leaks and prevent heat gain.\n",
            "4. **Cellulose insulation**: Cellulose is a eco-friendly, fire-resistant insulation made from recycled paper products. It's an excellent choice for hot climates because it's breathable, reducing the risk of moisture accumulation and related issues.\n",
            "5. **Rigid foam board**: Rigid foam board insulation, such as extruded polystyrene foam (XPS) or polyisocyanurate (PIR), is a durable, water-resistant option for exterior walls, foundations, and basements.\n",
            "6. **Insulated concrete forms (ICFs)**: ICFs are a type of building material that combines insulation with structural integrity. They provide excellent thermal mass, reducing the need for additional insulation in hot climates.\n",
            "7. **Vacuum insulation panels (VIPs)**: VIPs are high-performance insulation panels that use evacuated air spaces to reduce heat transfer. They're ideal for hot climates because they provide high R-values and can be used in walls, floors, and ceilings.\n",
            "8. **Phase change materials (PCMs)**: PCMs are materials that absorb and release heat as they change phase from solid to liquid or vice versa. They can be integrated into building materials, such as drywall or roofing, to reduce peak temperature fluctuations.\n",
            "\n",
            "When selecting an insulation material for a hot climate, consider factors such as:\n",
            "\n",
            "* R-value: A higher R-value indicates better thermal resistance.\n",
            "* Moisture resistance:\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "api_key = userdata.get('groq_key')\n",
        "url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"llama3-70b-8192\",\n",
        "    \"messages\": [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in materials and engineering.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What are the best insulation materials for hot climates?\"}\n",
        "    ],\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 512\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6KfLZcGGMoW"
      },
      "source": [
        "# Set environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fePnUkVjGMoW"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import time\n",
        "initial_time = time.time()\n",
        "import os\n",
        "\n",
        "os.environ[\"Mistral_API_KEY\"] = userdata.get('Mistal_OCR')\n",
        "os.environ[\"OLLAMA_HOST\"] = \"localhost:11434\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1jndo9oGMoX"
      },
      "source": [
        "# Setup Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8l98ZPnUM1z",
        "outputId": "a8421ae8-a67c-405e-a1e5-b48aeaa1f91d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-21-2514083021.py:61: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
            "  ollama_emb = OllamaEmbeddings(\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "import pypdf\n",
        "\n",
        "\n",
        "# Existing web URLs\n",
        "urls = [\n",
        "    \"https://www.epa.gov/smartgrowth/green-building\",\n",
        "    \"https://edgebuildings.com/\",\n",
        "    \"https://worldgbc.org/mena/\",\n",
        "    \"http://nrea.gov.eg/\",\n",
        "    \"https://www.greenmatch.co.uk/blog/green-building-materials\",\n",
        "    \"https://www.undp.org/egypt/environment-climate-change\",\n",
        "    \"https://www.frontiersin.org/journals/built-environment/articles/10.3389/fbuil.2023.1058782/full\",\n",
        "    \"https://www.priva.com/blog/buildings/healthy-buildings#:~:text=have%20been%20helpfully%20consolidated%20into,Health%2C%20Ventilation%20and%20Water%20Quality\",\n",
        "    \"https://worldgbc.org/healthy-equity-resilience/health-framework/#:~:text=Protect%20and%20Improve%20Health%2C%20exploring%3A,mental%20health%20and%20infectious%20disease\",\n",
        "    \"https://worldgbc.org/article/doing-right-by-planet-and-people-the-business-case-for-health-and-wellbeing-in-green-building/#:~:text=The%C2%A0report%C2%A0examines%20case%20studies%20of%2011,walls%20and%20extensive%20indoor%20plants\",\n",
        "    \"https://www.sciencedirect.com/science/article/abs/pii/S0378778818328986\",\n",
        "\n",
        "]\n",
        "\n",
        "# Load web documents\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "web_docs = []\n",
        "for url in urls:\n",
        "    loader = WebBaseLoader(url)\n",
        "    web_docs.extend(loader.load())\n",
        "\n",
        "# Load PDF documents\n",
        "pdf_paths = [\"/content/01-Energy-Efficiency-Urban-Planning-Guidelines-for-MENA-region-October-2013.pdf\",\n",
        "             \"/content/1-Evaluation-of-the-Sustainable-Building-Materials-for-Economic-Housing-in-Egypt.pdf\",\n",
        "             \"/content/Alternative-Building-Materials-for-Affordable-Housing-in-Egypt.pdf\",\n",
        "             \"/content/The_Future_of_Green_Building_Materials_i.pdf\",\n",
        "             \"/content/The_Appropriate_Building_Materials_for_E.pdf\",\n",
        "             \"/content/9_Foundations_of_a_Healthy_Building_February_2017_R1.8.pdf\",\n",
        "             \"/content/WorldGBC-Health-Wellbeing-Framework_Exec-Report_FINAL.pdf\",\n",
        "             \"/content/WorldGBC-Doing-Right-by-Planet-and-People.pdf\"\n",
        "\n",
        "             ]\n",
        "pdf_docs = []\n",
        "for path in pdf_paths:\n",
        "    try:\n",
        "        loader = PyPDFLoader(path)\n",
        "        pdf_docs.extend(loader.load())\n",
        "    except pypdf.errors.PdfReadError as e:\n",
        "        print(f\"Error loading PDF {path}: {e}\")\n",
        "        # You can choose to skip the file, log the error, or take other actions\n",
        "\n",
        "# Combine web and PDF documents\n",
        "all_docs = web_docs + pdf_docs\n",
        "\n",
        "\n",
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "#preprocess\n",
        "doc_splits = text_splitter.split_documents(all_docs)\n",
        "\n",
        "ollama_emb = OllamaEmbeddings(\n",
        "    model=\"nomic-embed-text\",\n",
        "    base_url=\"http://localhost:11434\",\n",
        "    embed_instruction=\"passage: \",\n",
        ")\n",
        "vectorstore = Chroma.from_documents(documents=doc_splits, collection_name=\"rag-chroma-new\", embedding=ollama_emb)\n",
        "\n",
        "# Create retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "retriever.search_kwargs = {\"k\": 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5P_KINgbHPr",
        "outputId": "0105cc65-5479-4ff0-8820-77fda0199f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-22-2507621586.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  test_docs = retriever.get_relevant_documents(\"What are green materials?\")\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Result 1 ---\n",
            "Source: /content/The_Future_of_Green_Building_Materials_i.pdf\n",
            "Content snippet:\n",
            "and impossible to distinctly pronounce. However, there is a complexity of variables that contribute to the greenness \n",
            "of a material and how to apply these principles in design and building. (Fithian, 2009)  \n",
            "Generally, a Green Building Material could be defined as:  \n",
            "“A green material is one that simultaneously does the most with the least, fits most harmoniously within ecosystem …\n",
            "\n",
            "--- Result 2 ---\n",
            "Source: /content/The_Future_of_Green_Building_Materials_i.pdf\n",
            "Content snippet:\n",
            "3.1. What is a Green Building Material? \n",
            "At present, there seems to be a lot of confusion in defining green m aterials. The process of determining exactly how \n",
            "green specific materials are is very complicated. The trouble in identifying the truest definition of green may be that \n",
            "there is no absolute definition. The lack of public unity in a definition ha s caused the meaning to become convoluted …\n",
            "\n",
            "--- Result 3 ---\n",
            "Source: /content/Alternative-Building-Materials-for-Affordable-Housing-in-Egypt.pdf\n",
            "Content snippet:\n",
            "Chapter three \n",
            "40 \n",
            " \n",
            "they have no access to information, technology or technical advice. Green or \n",
            "sustainable material can either be a completely new innovation, a modification \n",
            "to the production process of an existing material, or a new construction \n",
            "technique. The following table shows some of the existing innovations in the \n",
            "field of sustainable building materials in construction in Egypt. \n",
            "  \n",
            " \n",
            " \n",
            "Building \n",
            "component \n",
            "Material Application Aspects of \n",
            "sustainability \n",
            "Obstacles / \n",
            "limitations …\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_docs = retriever.get_relevant_documents(\"What are green materials?\")\n",
        "for i, doc in enumerate(test_docs, start=1):\n",
        "    print(f\"--- Result {i} ---\")\n",
        "    print(\"Source:\", doc.metadata.get(\"source\", \"unknown\"))\n",
        "    print(\"Content snippet:\")\n",
        "    print(doc.page_content[:], \"…\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxqu9D1nVzZY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import re\n",
        "from pathlib import Path\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "import pypdf\n",
        "from mistralai import Mistral\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from IPython.core.display import display, Markdown\n",
        "\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "api_key = userdata.get('Mistal_OCR')\n",
        "os.environ[\"MISTRAL_API_KEY\"] = api_key\n",
        "\n",
        "def build_pdf_chain(pdf_path: str):\n",
        "    \"\"\"\n",
        "    Process a floor plan PDF by performing OCR, summarizing images, and building\n",
        "    a retrieval-augmented generation (RAG) chain for interactive Q&A.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): The path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "        rag_pdf_chain: A retrieval chain object for answering queries.\n",
        "    \"\"\"\n",
        "    # ----------------------------\n",
        "    # Initialize the Mistral client and Chat LLM\n",
        "    # ----------------------------\n",
        "    try:\n",
        "        client = Mistral(api_key=api_key)\n",
        "        llm = ChatMistralAI(model=\"mistral-large-latest\", streaming=True)\n",
        "    except Exception as e:\n",
        "        logger.error(\"Error initializing Mistral client or ChatMistralAI.\", exc_info=True)\n",
        "        raise e\n",
        "\n",
        "    # ----------------------------\n",
        "    # Upload PDF for OCR processing\n",
        "    # ----------------------------\n",
        "    try:\n",
        "        logger.info(\"Uploading PDF for OCR processing...\")\n",
        "        with open(pdf_path, \"rb\") as f:\n",
        "            uploaded_pdf = client.files.upload(\n",
        "                file={\n",
        "                    \"file_name\": pdf_path,\n",
        "                    \"content\": f,\n",
        "                },\n",
        "                purpose=\"ocr\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        logger.error(\"Error uploading PDF.\", exc_info=True)\n",
        "        raise e\n",
        "\n",
        "    try:\n",
        "        client.files.retrieve(file_id=uploaded_pdf.id)\n",
        "        signed_url = client.files.get_signed_url(file_id=uploaded_pdf.id)\n",
        "    except Exception as e:\n",
        "        logger.error(\"Error retrieving or signing URL for the uploaded PDF.\", exc_info=True)\n",
        "        raise e\n",
        "\n",
        "    # ----------------------------\n",
        "    # OCR Processing\n",
        "    # ----------------------------\n",
        "    try:\n",
        "        logger.info(\"Processing OCR on the PDF...\")\n",
        "        ocr_response = client.ocr.process(\n",
        "            model=\"mistral-ocr-latest\",\n",
        "            document={\n",
        "                \"type\": \"document_url\",\n",
        "                \"document_url\": signed_url.url,\n",
        "            },\n",
        "            include_image_base64=True\n",
        "        )\n",
        "        logger.info(\"OCR processing completed successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(\"Error during OCR processing.\", exc_info=True)\n",
        "        raise e\n",
        "\n",
        "    # ----------------------------\n",
        "    # Image Summarization Helper Functions\n",
        "    # ----------------------------\n",
        "    def image_summarization(client, base64_image: str) -> str:\n",
        "        \"\"\"\n",
        "        Summarize an image (encoded in base64) using a specialized model.\n",
        "\n",
        "        Args:\n",
        "            client: The Mistral client.\n",
        "            base64_image (str): Base64-encoded image data.\n",
        "\n",
        "        Returns:\n",
        "            str: A text summary of the image.\n",
        "        \"\"\"\n",
        "        model = \"pixtral-12b-2409\"\n",
        "        prompt = (\n",
        "            \"You are an expert in architectural plans. Analyze the content of the image and provide a detailed summary. \"\n",
        "            \"Include descriptions of any visible text, objects, diagrams, graphs, or charts. The summary should be in the same \"\n",
        "            \"language as the original image and be text only.\"\n",
        "        )\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "        try:\n",
        "            chat_response = client.chat.complete(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                max_tokens=1000,\n",
        "                temperature=0.01\n",
        "            )\n",
        "            return chat_response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            logger.error(\"Error in image summarization.\", exc_info=True)\n",
        "            return \"Image summarization failed.\"\n",
        "\n",
        "    def clean_base64(base64_str: str) -> str:\n",
        "        \"\"\"Remove the base64 prefix if it exists.\"\"\"\n",
        "        prefix = 'data:image/jpeg;base64,'\n",
        "        if base64_str.startswith(prefix):\n",
        "            return base64_str.replace(prefix, '')\n",
        "        return base64_str\n",
        "\n",
        "    def replace_images_with_summary_in_markdown(ocr_response, client) -> str:\n",
        "        \"\"\"\n",
        "        Replace markdown image references in the OCR output with text summaries.\n",
        "\n",
        "        Args:\n",
        "            ocr_response: The OCR response containing pages with markdown and images.\n",
        "            client: The Mistral client for image summarization.\n",
        "\n",
        "        Returns:\n",
        "            str: The final consolidated markdown with image summaries.\n",
        "        \"\"\"\n",
        "        updated_markdown_list = []\n",
        "        for page_index, page in enumerate(ocr_response.pages):\n",
        "            markdown = page.markdown\n",
        "            images = page.images\n",
        "            image_base64_dict = {image.id: image.image_base64 for image in images}\n",
        "\n",
        "            def replace(match):\n",
        "                img_id = match.group(1)\n",
        "                base64_data = image_base64_dict.get(img_id)\n",
        "                if base64_data:\n",
        "                    cleaned_base64 = clean_base64(base64_data)\n",
        "                    image_summary = image_summarization(client, cleaned_base64)\n",
        "                    return f'[Image Summary: {img_id}] - {image_summary}'\n",
        "                return match.group(0)\n",
        "\n",
        "            updated_markdown = re.sub(r'!\\[.*?\\]\\((.*?)\\)', replace, markdown)\n",
        "            updated_markdown_list.append(updated_markdown)\n",
        "            display(Markdown(updated_markdown))  # Display for debugging/verification\n",
        "        final_markdown = \"\\n\\n\".join(updated_markdown_list)\n",
        "        return final_markdown\n",
        "\n",
        "    # Replace images in the OCR markdown with summaries\n",
        "    ocr_markdown = replace_images_with_summary_in_markdown(ocr_response, client)\n",
        "\n",
        "    # ----------------------------\n",
        "    # PDF Text Extraction using PyPDFLoader\n",
        "    # ----------------------------\n",
        "    pdf_text = \"\"\n",
        "    all_docs = []\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        docs = loader.load()\n",
        "        all_docs.extend(docs)\n",
        "        logger.info(f\"Loaded {len(all_docs)} document(s) from {pdf_path}\")\n",
        "        pdf_text = \"\\n\\n\".join([doc.page_content for doc in all_docs])\n",
        "    except pypdf.errors.PdfStreamError as e:\n",
        "        logger.error(\"Skipping corrupted or incomplete PDF.\", exc_info=True)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Combine OCR Markdown and PDF Text\n",
        "    # ----------------------------\n",
        "    combined_text = ocr_markdown + \"\\n\\n\" + pdf_text\n",
        "\n",
        "    # ----------------------------\n",
        "    # Text Splitting and Vectorization\n",
        "    # ----------------------------\n",
        "    # Adjusted chunk size and overlap for better context capture\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    chunks = text_splitter.split_text(combined_text)\n",
        "    documents = [Document(page_content=chunk) for chunk in chunks]\n",
        "    logger.info(f\"Total text chunks created: {len(documents)}\")\n",
        "\n",
        "    try:\n",
        "        # Using a different embedding model to capture more nuanced details\n",
        "        markdown_vectorstore = Chroma.from_documents(\n",
        "            documents=documents,\n",
        "            embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-mpnet-base-v2\")\n",
        "        )\n",
        "        retriever = markdown_vectorstore.as_retriever()\n",
        "        # Increase the number of nearest neighbors to retrieve more context\n",
        "        retriever.search_kwargs = {\"k\": 10}\n",
        "        logger.info(\"Vector store and retriever created successfully.\")\n",
        "    except Exception as e:\n",
        "        logger.error(\"Error creating vector store.\", exc_info=True)\n",
        "        raise e\n",
        "\n",
        "    # ----------------------------\n",
        "    # Build the Retrieval-Augmented Generation (RAG) Chain\n",
        "    # ----------------------------\n",
        "    system_prompt = (\n",
        "        \"You are an assistant skilled in interpreting floor plans and architectural documents. \"\n",
        "        \"Use the following retrieved context, which includes detailed image summaries and OCR text, \"\n",
        "        \"to answer the question. Analyze architectural details carefully. \"\n",
        "        \"If you do not have enough information, say that you do not know.\\n\\n\"\n",
        "        \"{context}\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "    logger.info(\"Creating RAG chain...\")\n",
        "    try:\n",
        "        rag_pdf_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "        logger.info(\"RAG chain created successfully.\")\n",
        "        return rag_pdf_chain\n",
        "    except Exception as e:\n",
        "        logger.error(\"Error creating RAG chain.\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRh44QXjGMoY"
      },
      "source": [
        "# Create Retriever Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzCRTno82YHC"
      },
      "outputs": [],
      "source": [
        "pdf_path = \"/content/House-Floor-Plans.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b7CN35GGMoZ"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain.tools import Tool\n",
        "\n",
        "\n",
        "pdf_question_answering_tool = Tool(\n",
        "    name=\"pdf_question_answering_tool\",\n",
        "    description=\"Retrieve information from the uploaded PDF.\",\n",
        "    func=lambda inputs: build_pdf_chain(pdf_path).invoke(\n",
        "        {\"input\": inputs[\"query\"]} if isinstance(inputs, dict) else {\"input\": inputs}\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever=retriever,\n",
        "    name=\"retrieve_green_building_info\",\n",
        "    description=(\n",
        "        \"Search and return information from uploaded documents (including PDFs) and web sources \"\n",
        "        \"related to green building practices, sustainable architecture, and environmental standards \"\n",
        "        \"in Egypt and the Middle East and provide long detailed answer.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "tools = [pdf_question_answering_tool, retriever_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E99UlfbM7YJj"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "saLHrtQuuiRE",
        "outputId": "e52074cb-c7fc-4b46-e4f1-ac21a701d3de"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'TOOL_MESSAGE_BLOCK_TYPES' from 'langchain_core.tools.base' (/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-2789580747.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_retriever_tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_messages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebuilt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtools_condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebuilt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToolNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"langgraph.prebuilt exposes a higher-level API for creating and executing agents and tools.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebuilt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_agent_executor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_react_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m from langgraph.prebuilt.tool_node import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mInjectedState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/chat_agent_executor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompiledStateGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanaged\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIsLastStep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRemainingSteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprebuilt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_node\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToolNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/prebuilt/tool_node.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseTool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInjectedToolArg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcreate_tool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m from langchain_core.tools.base import (\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mTOOL_MESSAGE_BLOCK_TYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mget_all_basemodel_annotations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'TOOL_MESSAGE_BLOCK_TYPES' from 'langchain_core.tools.base' (/usr/local/lib/python3.11/dist-packages/langchain_core/tools/base.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from typing import Literal, Annotated, Sequence, Any, Dict\n",
        "from typing_extensions import TypedDict\n",
        "from langchain import hub\n",
        "from langchain_core.messages import HumanMessage, BaseMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "# Replace Ollama with Groq\n",
        "from langchain_groq import ChatGroq\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.tools import Tool\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "from langgraph.prebuilt import ToolNode\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_key')\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    tools: Sequence[Tool]\n",
        "\n",
        "\n",
        "### Edges\n",
        "def grade_documents(state) -> Literal[\"generate\", \"rewrite\"]:\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "    \"\"\"\n",
        "    print(\"---CHECK RELEVANCE---\")\n",
        "\n",
        "    class Grade(BaseModel):\n",
        "        binary_score: str = Field(\n",
        "            description=\"Relevance score: 'yes' or 'no'\"\n",
        "        )\n",
        "\n",
        "    model = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
        "    llm_with_tool = model.with_structured_output(Grade)\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        template=(\n",
        "            \"You are a grader assessing relevance of a retrieved document to a user question. \\n\"\n",
        "            \"Here is the retrieved document: \\n\\n {context} \\n\\n\"\n",
        "            \"Here is the user question: {question} \\n\"\n",
        "            \"If the document contains keyword(s) or semantic meaning related to the user question, \"\n",
        "            \"grade it as relevant. \\n\"\n",
        "            \"Give a binary score 'yes' or 'no' to indicate whether the document is relevant to the question.\"\n",
        "        ),\n",
        "        input_variables=[\"context\", \"question\"],\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm_with_tool\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    question = messages[0].content\n",
        "    docs = last_message.content\n",
        "\n",
        "    scored_result = chain.invoke({\"question\": question, \"context\": docs})\n",
        "    score = scored_result.binary_score.strip().lower()\n",
        "\n",
        "    if score == \"yes\":\n",
        "        print(\"---DECISION: DOCS RELEVANT---\")\n",
        "        return \"generate\"\n",
        "    else:\n",
        "        print(\"---DECISION: DOCS NOT RELEVANT---\")\n",
        "        print(score)\n",
        "        return \"rewrite\"\n",
        "\n",
        "### Nodes\n",
        "def agent(state):\n",
        "    \"\"\"\n",
        "    Invokes the agent model to generate a response based on the current state.\n",
        "    \"\"\"\n",
        "    print(\"---CALL AGENT---\")\n",
        "    messages = state[\"messages\"]\n",
        "    model = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
        "\n",
        "    model = model.bind_tools(tools)\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    return {\n",
        "        \"messages\": [response],\n",
        "        \"tools\": tools\n",
        "    }\n",
        "\n",
        "def rewrite(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "    \"\"\"\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "\n",
        "    msg = [\n",
        "        HumanMessage(\n",
        "            content=(\n",
        "                \"\\nLook at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
        "                \"Here is the initial question:\\n\"\n",
        "                \"-------\\n\"\n",
        "                f\"{question}\\n\"\n",
        "                \"-------\\n\"\n",
        "                \"Formulate an improved question:\"\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    model = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
        "    response = model.invoke(msg)\n",
        "    return {\"messages\": [response], \"tools\": state.get(\"tools\", tools)}\n",
        "\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate an answer based on the question and retrieved documents.\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    messages = state[\"messages\"]\n",
        "    question = messages[0].content\n",
        "    last_message = messages[-1]\n",
        "    docs = last_message.content\n",
        "\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "    llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
        "\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "\n",
        "    return {\"messages\": [response], \"tools\": state.get(\"tools\", tools)}\n",
        "\n",
        "def info_only(state):\n",
        "    \"\"\"\n",
        "    Directly return the output from the tool if the user only wants information.\n",
        "    \"\"\"\n",
        "    print(\"---INFO ONLY---\")\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    docs = last_message.content\n",
        "\n",
        "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "    llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0)\n",
        "    rag_chain = prompt | llm | StrOutputParser()\n",
        "    response = rag_chain.invoke({\"context\": docs, \"question\": messages[0].content})\n",
        "\n",
        "    print(response)\n",
        "    return {\"messages\": [response], \"tools\": state.get(\"tools\", tools)}\n",
        "\n",
        "def custom_tools_condition(state):\n",
        "    \"\"\"\n",
        "    Custom condition for routing based on user input and tool usage.\n",
        "\n",
        "    This examines the user's query to determine the next step based on keywords.\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    user_message = messages[0].content.lower()\n",
        "\n",
        "    last_message = messages[-1]\n",
        "    has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls\n",
        "\n",
        "    print(f\"User message: {user_message}\")\n",
        "    print(f\"Has tool calls: {has_tool_calls}\")\n",
        "    if has_tool_calls:\n",
        "        print(f\"Tool name: {last_message.tool_calls[0]['name']}\")\n",
        "\n",
        "    info_keywords = [\"inform\", \"tell me\", \"what is\", \"describe\", \"explanation\", \"details about\"]\n",
        "    recommend_keywords = [\"recommend\", \"suggest\", \"find\", \"search\", \"retrieve\", \"get\", \"looking for\"]\n",
        "\n",
        "    info_intent = any(keyword in user_message for keyword in info_keywords)\n",
        "    recommend_intent = any(keyword in user_message for keyword in recommend_keywords)\n",
        "\n",
        "    print(f\"Info intent: {info_intent}\")\n",
        "    print(f\"Recommend intent: {recommend_intent}\")\n",
        "\n",
        "    if has_tool_calls:\n",
        "        tool_name = last_message.tool_calls[0]['name'].lower()\n",
        "        if tool_name == \"pdf_question_answering_tool\":\n",
        "            return \"info\"\n",
        "        else:\n",
        "            return \"recommend\"\n",
        "\n",
        "    if recommend_intent:\n",
        "        return \"recommend\"\n",
        "    elif info_intent:\n",
        "        return \"info\"\n",
        "    else:\n",
        "        return \"end\"\n",
        "\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"agent\", agent)\n",
        "workflow.add_node(\n",
        "    \"retrieve\",\n",
        "    ToolNode([retriever_tool])\n",
        ")\n",
        "workflow.add_node(\"rewrite\", rewrite)\n",
        "workflow.add_node(\"generate\", generate)\n",
        "workflow.add_node(\"info_only\", ToolNode([pdf_question_answering_tool]))\n",
        "\n",
        "# Build edges\n",
        "workflow.add_edge(START, \"agent\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    custom_tools_condition,\n",
        "    {\n",
        "        \"recommend\": \"retrieve\",\n",
        "        \"info\": \"info_only\",\n",
        "        \"end\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"retrieve\",\n",
        "    grade_documents,\n",
        "    {\n",
        "        \"generate\": \"generate\",\n",
        "        \"rewrite\": \"rewrite\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# On generate, end workflow\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "# Loop info_only back to agent for continued user questions\n",
        "workflow.add_edge(\"info_only\", END)\n",
        "\n",
        "# On rewrite, loop back to agent with new RAGState\n",
        "workflow.add_edge(\"rewrite\", \"agent\")\n",
        "\n",
        "graph = workflow.compile()\n",
        "\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass\n",
        "\n",
        "# Sample inputs to test the graph (uncomment to use)\n",
        "# inputs = {\n",
        "#     \"messages\": [\n",
        "#         HumanMessage(content=\"Tell me about green building practices in Egypt\")\n",
        "#     ],\n",
        "#     \"tools\": tools\n",
        "# }\n",
        "#\n",
        "# for output in graph.stream(inputs):\n",
        "#     for key, value in output.items():\n",
        "#         print(f\"Output from node '{key}':\")\n",
        "#         print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XHXvcvU7m_9"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"suggest energy efficiency urban planning\")\n",
        "    ],\n",
        "}\n",
        "\n",
        "for output in graph.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        pprint.pprint(f\"Output from node '{key}':\")\n",
        "        pprint.pprint(\"---\")\n",
        "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint.pprint(\"\\n---\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ch5sMJ9QhPrZ"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "inputs = {\n",
        "    \"messages\": [\n",
        "        HumanMessage(content=\"suggest energy efficiency urban planning\")\n",
        "    ],\n",
        "}\n",
        "\n",
        "for output in graph.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "      if key == 'generate':\n",
        "        print(value[\"messages\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEmhuZg7i4t8"
      },
      "source": [
        "# **API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlE2XUJcFaa9"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "def retrieval_classifier(prompt: str):\n",
        "  api_key = userdata.get('MistalKey')\n",
        "\n",
        "  if not api_key:\n",
        "      raise ValueError(\"MISTRAL_API_KEY environment variable is not set.\")\n",
        "\n",
        "  client = Mistral(api_key=api_key)\n",
        "\n",
        "  model = \"mistral-large-latest\"\n",
        "\n",
        "\n",
        "  classification_prompt = (\n",
        "      \"You are a classifier that determines if a user prompt is asking \"\n",
        "      \"about uploaded documents or not.\\n\"\n",
        "      \"If the prompt is intended to search, analyze, or refer to uploaded files, \"\n",
        "      \"return exactly: true\\n\"\n",
        "      \"If it is a general question with no reference to uploaded documents, return exactly: false\\n\"\n",
        "      \"Only respond with one word: true or false.\\n\\n\"\n",
        "      f\"Prompt: {prompt}\"\n",
        "  )\n",
        "\n",
        "  messages = [\n",
        "      {\"role\": \"user\", \"content\": classification_prompt}\n",
        "  ]\n",
        "\n",
        "  chat_response = client.chat.complete(\n",
        "      model=model,\n",
        "      messages=messages,\n",
        "      temperature=0.0\n",
        "  )\n",
        "\n",
        "  response = chat_response.choices[0].message.content.strip().lower()\n",
        "  return response\n",
        "\n",
        "# print(\"Retrieval Intent:\", retrieval_classifier(\"tell me about the file\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKZvsRH8Khe4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import logging\n",
        "from flask import Flask, request, Response, jsonify\n",
        "from flask_cors import CORS\n",
        "from werkzeug.utils import secure_filename\n",
        "import time\n",
        "from pathlib import Path\n",
        "from supabase import create_client, Client\n",
        "from functools import wraps\n",
        "import jwt\n",
        "from datetime import datetime\n",
        "from langchain_core.messages import HumanMessage\n",
        "from typing import Generator\n",
        "import threading\n",
        "import queue\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "CORS(\n",
        "    app,\n",
        "    resources={\n",
        "        r\"/api/*\": {\n",
        "            \"origins\": [\"http://localhost:4200\"],\n",
        "            \"supports_credentials\": True,\n",
        "            \"allow_headers\": [\"Content-Type\", \"Authorization\", \"Accept\"],\n",
        "            \"methods\": [\"GET\", \"POST\", \"OPTIONS\"],\n",
        "            \"expose_headers\": [\"Content-Type\"],\n",
        "        }\n",
        "    },\n",
        "    send_wildcard=False\n",
        ")\n",
        "\n",
        "UPLOAD_FOLDER = './uploads'\n",
        "ALLOWED_EXTENSIONS = {'pdf', 'txt', 'doc', 'docx'}\n",
        "MAX_CONTENT_LENGTH = 16 * 1024 * 1024\n",
        "\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "app.config['MAX_CONTENT_LENGTH'] = MAX_CONTENT_LENGTH\n",
        "\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "SUPABASE_URL = userdata.get('SUPABASE_URL')\n",
        "SUPABASE_KEY = userdata.get('SUPABASE_KEY')\n",
        "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "def format_timestamp(dt):\n",
        "    if isinstance(dt, str):\n",
        "        dt = datetime.fromisoformat(dt.replace('Z', '+00:00'))\n",
        "    return dt.strftime('%I:%M %p')\n",
        "\n",
        "def require_auth(f):\n",
        "    @wraps(f)\n",
        "    def decorated(*args, **kwargs):\n",
        "        token = None\n",
        "        auth_header = request.headers.get('Authorization')\n",
        "        if auth_header and auth_header.startswith('Bearer '):\n",
        "            token = auth_header.split(' ')[1]\n",
        "\n",
        "        if not token:\n",
        "            return jsonify({\"error\": \"Authorization token is missing\"}), 401\n",
        "\n",
        "        try:\n",
        "            user = supabase.auth.get_user(token)\n",
        "            request.user_id = user.user.id\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Token verification failed: {str(e)}\")\n",
        "            return jsonify({\"error\": \"Invalid token\"}), 401\n",
        "\n",
        "        return f(*args, **kwargs)\n",
        "    return decorated\n",
        "\n",
        "@app.route('/api/signup', methods=['POST'])\n",
        "def signup():\n",
        "    \"\"\"User signup endpoint.\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        email = data.get('email')\n",
        "        password = data.get('password')\n",
        "\n",
        "        if not email or not password:\n",
        "            return jsonify({\"error\": \"Email and password are required\"}), 400\n",
        "\n",
        "        response = supabase.auth.sign_up({\n",
        "            \"email\": email,\n",
        "            \"password\": password\n",
        "        })\n",
        "\n",
        "        if response.user:\n",
        "            return jsonify({\"message\": \"User created successfully\", \"user_id\": response.user.id}), 201\n",
        "        else:\n",
        "            return jsonify({\"error\": \"Signup failed\"}), 400\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Signup error: {str(e)}\", exc_info=True)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/login', methods=['POST'])\n",
        "def login():\n",
        "    \"\"\"User login endpoint.\"\"\"\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        email = data.get('email')\n",
        "        password = data.get('password')\n",
        "\n",
        "        if not email or not password:\n",
        "            return jsonify({\"error\": \"Email and password are required\"}), 400\n",
        "\n",
        "        response = supabase.auth.sign_in_with_password({\n",
        "            \"email\": email,\n",
        "            \"password\": password\n",
        "        })\n",
        "\n",
        "        if response.session:\n",
        "            return jsonify({\n",
        "                \"message\": \"Login successful\",\n",
        "                \"access_token\": response.session.access_token,\n",
        "                \"user_id\": response.user.id\n",
        "            }), 200\n",
        "        else:\n",
        "            return jsonify({\"error\": \"Invalid credentials\"}), 401\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Login error: {str(e)}\", exc_info=True)\n",
        "        return jsonify({\"error\": str(e)}), 401\n",
        "\n",
        "\n",
        "def generate_stream_response(\n",
        "    user_id: str,\n",
        "    user_message: str,\n",
        "    selected_tools: list,\n",
        "    is_retrieval: bool,\n",
        "    chat_id: str = None\n",
        ") -> Generator[str, None, None]:\n",
        "    import datetime\n",
        "\n",
        "    inputs = {\n",
        "        \"messages\": [HumanMessage(content=user_message)],\n",
        "        \"tools\": selected_tools if is_retrieval else []\n",
        "    }\n",
        "\n",
        "    response_text = \"\"\n",
        "    ai_sent = False\n",
        "\n",
        "    for output in graph.stream(inputs):\n",
        "        for node_name, state in output.items():\n",
        "            if node_name == \"generate\":\n",
        "                messages = state.get(\"messages\", [])\n",
        "                if messages:\n",
        "                    content = messages[-1].content if hasattr(messages[-1], 'content') else str(messages[-1])\n",
        "\n",
        "                    response_text += content\n",
        "                    payload = {\"content\": content}\n",
        "                    sse_data = f\"data: {json.dumps(payload)}\\n\\n\"\n",
        "                    yield sse_data\n",
        "                    ai_sent = True\n",
        "\n",
        "    if chat_id:\n",
        "        supabase.table(\"messages\").insert({\n",
        "            \"chat_id\": chat_id,\n",
        "            \"sender\": \"User\",\n",
        "            \"message\": user_message,\n",
        "            \"created_at\": datetime.datetime.utcnow().isoformat()\n",
        "        }).execute()\n",
        "\n",
        "        if ai_sent:\n",
        "            supabase.table(\"messages\").insert({\n",
        "                \"chat_id\": chat_id,\n",
        "                \"sender\": \"AI\",\n",
        "                \"message\": response_text,\n",
        "                \"created_at\": datetime.datetime.utcnow().isoformat()\n",
        "            }).execute()\n",
        "\n",
        "    if not ai_sent:\n",
        "        yield 'data: {\"content\": \"No \\'generate\\' node output found.\"}\\n\\n'\n",
        "\n",
        "\n",
        "@app.route('/api/message', methods=['POST'])\n",
        "@require_auth\n",
        "def handle_message():\n",
        "    print(\"Request hit /api/message\")\n",
        "\n",
        "    try:\n",
        "        if not request.is_json:\n",
        "            return jsonify({\"error\": \"Request must be JSON\"}), 400\n",
        "\n",
        "        data = request.get_json()\n",
        "        message = data.get('message', '').strip()\n",
        "        if not message:\n",
        "            return jsonify({\"error\": \"Message cannot be empty\"}), 400\n",
        "\n",
        "        print(f\"Received message: {message}\")\n",
        "\n",
        "        intent = retrieval_classifier(message)\n",
        "        print(f\"Retrieval Intent: {intent}\")\n",
        "\n",
        "        is_retrieval = intent == 'true'\n",
        "        user_id = request.user_id\n",
        "        chat_id = data.get('chat_id')\n",
        "        return Response(\n",
        "            generate_stream_response(user_id, message, tools, is_retrieval, chat_id),\n",
        "            mimetype='text/plain',\n",
        "            content_type='text/event-stream',\n",
        "            headers={\n",
        "                'Cache-Control': 'no-cache',\n",
        "                'Connection': 'keep-alive',\n",
        "                'X-Accel-Buffering': 'no'\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in handle_message: {str(e)}\", exc_info=True)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "@app.route('/api/upload', methods=['POST'])\n",
        "@require_auth\n",
        "def handle_upload():\n",
        "    print(\"Request hit /api/upload\")\n",
        "    try:\n",
        "        if 'file' not in request.files:\n",
        "            return jsonify({\"error\": \"No file provided\"}), 400\n",
        "\n",
        "        file = request.files['file']\n",
        "        if file.filename == '':\n",
        "            return jsonify({\"error\": \"No file selected\"}), 400\n",
        "        if not file.filename.lower().endswith('.pdf'):\n",
        "            return jsonify({\"error\": \"Only PDF files are allowed\"}), 400\n",
        "\n",
        "        user_question = request.form.get('prompt', '').strip()\n",
        "        if not user_question:\n",
        "            return jsonify({\"error\": \"Please provide a question about the PDF\"}), 400\n",
        "\n",
        "        filename = secure_filename(file.filename)\n",
        "        file_path = os.path.join(app.config['UPLOAD_FOLDER'], f\"{int(time.time())}_{filename}\")\n",
        "        file.save(file_path)\n",
        "        print(f\"Saved file: {file_path}\")\n",
        "\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        pages = loader.load()\n",
        "        pdf_text = \"\\n\".join([page.page_content for page in pages])\n",
        "        if not pdf_text.strip():\n",
        "            return jsonify({\"error\": \"No extractable text found in PDF\"}), 400\n",
        "\n",
        "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "        chunks = splitter.split_text(pdf_text)\n",
        "        documents = [Document(page_content=chunk, metadata={\"source\": filename}) for chunk in chunks]\n",
        "\n",
        "        vectorstore.add_documents(documents=documents)\n",
        "        print(f\"Added {len(documents)} chunks to vector store.\")\n",
        "\n",
        "        user_id = request.user_id\n",
        "        chat_id = request.form.get('chat_id')\n",
        "\n",
        "        return Response(\n",
        "            generate_stream_response(user_id, user_question, tools, True, chat_id),\n",
        "            mimetype='text/plain',\n",
        "            content_type='text/event-stream',\n",
        "            headers={\n",
        "                'Cache-Control': 'no-cache',\n",
        "                'Connection': 'keep-alive',\n",
        "                'X-Accel-Buffering': 'no'\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Upload handler error: {str(e)}\", exc_info=True)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# Chat Endpoints\n",
        "\n",
        "@app.route('/api/chats', methods=['POST'])\n",
        "@require_auth\n",
        "def create_chat():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        title = data.get('title', '').strip()\n",
        "\n",
        "        if not title:\n",
        "            return jsonify({\"error\": \"Chat title is required\"}), 400\n",
        "\n",
        "        response = supabase.table('chats').insert({\n",
        "            'user_id': request.user_id,\n",
        "            'title': title\n",
        "        }).execute()\n",
        "\n",
        "        if response.data:\n",
        "            chat = response.data[0]\n",
        "            return jsonify({\n",
        "                \"chat_id\": chat['id'],\n",
        "                \"title\": chat['title'],\n",
        "                \"messages\": []\n",
        "            }), 201\n",
        "        else:\n",
        "            return jsonify({\"error\": \"Failed to create chat\"}), 500\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error creating chat: {str(e)}\", exc_info=True)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/api/chats', methods=['GET'])\n",
        "@require_auth\n",
        "def get_chats():\n",
        "    try:\n",
        "        response = supabase.table('chats') \\\n",
        "            .select('id, title, messages(sender, message, image_url, created_at)') \\\n",
        "            .eq('user_id', request.user_id) \\\n",
        "            .order('updated_at', desc=True) \\\n",
        "            .execute()\n",
        "\n",
        "        if not response.data:\n",
        "            return jsonify([]), 200\n",
        "\n",
        "        chats_with_messages = []\n",
        "\n",
        "        for chat in response.data:\n",
        "            messages = sorted(chat.get('messages', []), key=lambda m: m['created_at'])\n",
        "            chats_with_messages.append({\n",
        "                \"id\": chat['id'],\n",
        "                \"title\": chat['title'],\n",
        "                \"messages\": [\n",
        "                    {\n",
        "                        \"sender\": msg['sender'],\n",
        "                        \"message\": msg['message'],\n",
        "                        \"image_url\": msg.get('image_url'),\n",
        "                        \"timestamp\": format_timestamp(msg['created_at'])\n",
        "                    } for msg in messages\n",
        "                ]\n",
        "            })\n",
        "\n",
        "        return jsonify(chats_with_messages), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error retrieving chats: {str(e)}\", exc_info=True)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "@app.route('/api/chats/<chat_id>', methods=['GET'])\n",
        "@require_auth\n",
        "def get_chat_messages(chat_id):\n",
        "    try:\n",
        "        chat_response = supabase.table('chats') \\\n",
        "            .select('id, title, created_at, updated_at') \\\n",
        "            .eq('id', chat_id) \\\n",
        "            .eq('user_id', request.user_id) \\\n",
        "            .single() \\\n",
        "            .execute()\n",
        "\n",
        "        if not chat_response.data:\n",
        "            return jsonify({\"error\": \"Chat not found\"}), 404\n",
        "\n",
        "        chat = chat_response.data\n",
        "\n",
        "        messages_response = supabase.table('messages') \\\n",
        "            .select('id, sender, message, image_url, created_at') \\\n",
        "            .eq('chat_id', chat_id) \\\n",
        "            .order('created_at', desc=False) \\\n",
        "            .execute()\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"message_id\": msg[\"id\"],\n",
        "                \"sender\": msg[\"sender\"],\n",
        "                \"message\": msg[\"message\"],\n",
        "                \"image_url\": msg.get(\"image_url\"),\n",
        "                \"message_created_at\": msg[\"created_at\"]\n",
        "            }\n",
        "            for msg in messages_response.data or []\n",
        "        ]\n",
        "\n",
        "        return jsonify({\n",
        "            \"chat_id\": chat[\"id\"],\n",
        "            \"title\": chat[\"title\"],\n",
        "            \"chat_created_at\": chat[\"created_at\"],\n",
        "            \"chat_updated_at\": chat[\"updated_at\"],\n",
        "            \"messages\": messages\n",
        "        }), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error retrieving chat messages: {str(e)}\", exc_info=True)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/api/health', methods=['GET'])\n",
        "def health_check():\n",
        "    return jsonify({\n",
        "        \"status\": \"healthy\",\n",
        "        \"timestamp\": time.time(),\n",
        "        \"version\": \"1.0.0\"\n",
        "    })\n",
        "\n",
        "@app.errorhandler(413)\n",
        "def too_large(e):\n",
        "    return jsonify({\"error\": \"File too large. Maximum size is 16MB.\"}), 413\n",
        "\n",
        "@app.errorhandler(404)\n",
        "def not_found(e):\n",
        "    return jsonify({\"error\": \"Endpoint not found\"}), 404\n",
        "\n",
        "@app.errorhandler(500)\n",
        "def internal_error(e):\n",
        "    logger.error(f\"Internal server error: {str(e)}\", exc_info=True)\n",
        "    return jsonify({\"error\": \"Internal server error\"}), 500\n",
        "\n",
        "def start_server():\n",
        "    ngrok.set_auth_token(userdata.get('NGROK_AUTH_TOKEN_2'))\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"API URL: {public_url.public_url}\")\n",
        "    print(f\"Message API URL: {public_url.public_url}/api/message\")\n",
        "    print(f\"Upload API URL: {public_url.public_url}/api/upload\")\n",
        "    print(f\"Chats API URL: {public_url.public_url}/api/chats\")\n",
        "\n",
        "    app.run(port=5000, threaded=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_server()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlFDrQnsjbFE"
      },
      "outputs": [],
      "source": [
        "!nohup bash -c \"OLLAMA_HOST=0.0.0.0:11434 OLLAMA_ORIGIN=* ollama serve\" &\n",
        "!sleep 5 && tail /content/nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ca8Yud8irQ28"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}